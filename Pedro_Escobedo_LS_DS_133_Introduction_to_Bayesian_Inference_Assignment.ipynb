{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pedro Escobedo LS_DS_133_Introduction_to_Bayesian_Inference_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroescobedob/DS-Unit-1-Sprint-3-Statistical-Tests-and-Experiments/blob/master/Pedro_Escobedo_LS_DS_133_Introduction_to_Bayesian_Inference_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 133\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "Most of the above was pure math - now write Python code to reproduce the results! This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up, and as a stretch goal - refactor your code into helpful reusable functions!\n",
        "\n",
        "Specific goals/targets:\n",
        "\n",
        "1. Write a function `def prob_drunk_given_positive(prob_drunk_prior, prob_positive, prob_positive_drunk)` that reproduces the example from lecture, and use it to calculate and visualize a range of situations\n",
        "2. Explore `scipy.stats.bayes_mvs` - read its documentation, and experiment with it on data you've tested in other ways earlier this week\n",
        "3. Create a visualization comparing the results of a Bayesian approach to a traditional/frequentist approach\n",
        "4. In your own words, summarize the difference between Bayesian and Frequentist statistics\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/) - you could and should create something similar!\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective\n",
        "- Check out [PyMC3](https://docs.pymc.io/) (note this goes beyond hypothesis tests into modeling) - read the guides and work through some examples\n",
        "- Take PyMC3 further - see if you can build something with it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - code!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kyc_a7pJIrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkQl1cZxG9dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_drunk_given_positive(prob_drunk_prior, prob_positive, prob_positive_drunk):\n",
        "  return (prob_positive_drunk * prob_drunk_prior)/prob_positive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra4BM_7BKiTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b213a36a-cfbf-4286-a496-7974486583d8"
      },
      "source": [
        "prob_drunk_given_positive(0.001, 0.08, 1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciou4UC2cCbh",
        "colab_type": "text"
      },
      "source": [
        "# scipy.stats.bayes_mvs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkCW45dzSgTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca870d8f-e302-4306-f3bb-941ac371abf7"
      },
      "source": [
        "help(stats.bayes_mvs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function bayes_mvs in module scipy.stats.morestats:\n",
            "\n",
            "bayes_mvs(data, alpha=0.9)\n",
            "    Bayesian confidence intervals for the mean, var, and std.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : array_like\n",
            "        Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
            "        Requires 2 or more data points.\n",
            "    alpha : float, optional\n",
            "        Probability that the returned confidence interval contains\n",
            "        the true parameter.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    mean_cntr, var_cntr, std_cntr : tuple\n",
            "        The three results are for the mean, variance and standard deviation,\n",
            "        respectively.  Each result is a tuple of the form::\n",
            "    \n",
            "            (center, (lower, upper))\n",
            "    \n",
            "        with `center` the mean of the conditional pdf of the value given the\n",
            "        data, and `(lower, upper)` a confidence interval, centered on the\n",
            "        median, containing the estimate to a probability ``alpha``.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    mvsdist\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Each tuple of mean, variance, and standard deviation estimates represent\n",
            "    the (center, (lower, upper)) with center the mean of the conditional pdf\n",
            "    of the value given the data and (lower, upper) is a confidence interval\n",
            "    centered on the median, containing the estimate to a probability\n",
            "    ``alpha``.\n",
            "    \n",
            "    Converts data to 1-D and assumes all data has the same mean and variance.\n",
            "    Uses Jeffrey's prior for variance and std.\n",
            "    \n",
            "    Equivalent to ``tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))``\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
            "    standard-deviation from data\", https://scholarsarchive.byu.edu/facpub/278,\n",
            "    2006.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    First a basic example to demonstrate the outputs:\n",
            "    \n",
            "    >>> from scipy import stats\n",
            "    >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
            "    >>> mean, var, std = stats.bayes_mvs(data)\n",
            "    >>> mean\n",
            "    Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))\n",
            "    >>> var\n",
            "    Variance(statistic=10.0, minmax=(3.176724206..., 24.45910382...))\n",
            "    >>> std\n",
            "    Std_dev(statistic=2.9724954732045084, minmax=(1.7823367265645143, 4.945614605014631))\n",
            "    \n",
            "    Now we generate some normally distributed random data, and get estimates of\n",
            "    mean and standard deviation with 95% confidence intervals for those\n",
            "    estimates:\n",
            "    \n",
            "    >>> n_samples = 100000\n",
            "    >>> data = stats.norm.rvs(size=n_samples)\n",
            "    >>> res_mean, res_var, res_std = stats.bayes_mvs(data, alpha=0.95)\n",
            "    \n",
            "    >>> import matplotlib.pyplot as plt\n",
            "    >>> fig = plt.figure()\n",
            "    >>> ax = fig.add_subplot(111)\n",
            "    >>> ax.hist(data, bins=100, density=True, label='Histogram of data')\n",
            "    >>> ax.vlines(res_mean.statistic, 0, 0.5, colors='r', label='Estimated mean')\n",
            "    >>> ax.axvspan(res_mean.minmax[0],res_mean.minmax[1], facecolor='r',\n",
            "    ...            alpha=0.2, label=r'Estimated mean (95% limits)')\n",
            "    >>> ax.vlines(res_std.statistic, 0, 0.5, colors='g', label='Estimated scale')\n",
            "    >>> ax.axvspan(res_std.minmax[0],res_std.minmax[1], facecolor='g', alpha=0.2,\n",
            "    ...            label=r'Estimated scale (95% limits)')\n",
            "    \n",
            "    >>> ax.legend(fontsize=10)\n",
            "    >>> ax.set_xlim([-4, 4])\n",
            "    >>> ax.set_ylim([0, 0.5])\n",
            "    >>> plt.show()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph1ShDULCfBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwCtQcBi9ZwM",
        "colab_type": "code",
        "outputId": "aaba0732-5450-447f-b8e1-18c2bd217dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "exercise_df = pd.read_csv('https://raw.githubusercontent.com/pedroescobedob/DS-Unit-1-Sprint-1-Dealing-With-Data/master/module3-databackedassertions/persons.csv')\n",
        "exercise_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>exercise_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>118</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>161</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>128</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>216</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  age  weight  exercise_time\n",
              "0           0   44     118            192\n",
              "1           1   41     161             35\n",
              "2           2   46     128            220\n",
              "3           3   39     216             57\n",
              "4           4   28     116            182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyvUSIR9bxkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "75617a2d-4d30-4043-f22f-c27b90822b9a"
      },
      "source": [
        "# print (\"\\Weight : \", exercise_df['weight']) \n",
        "# print (\"\\Exercise time : \", exercise_df['exercise_time']) \n",
        "  \n",
        "mean, var, std = stats.bayes_mvs(exercise_df['weight'], 0.9) \n",
        "  \n",
        "print (\"\\nMean of weight : \", mean) \n",
        "print (\"\\nvar of weight : \", var) \n",
        "print (\"\\nstd of weight : \", std) \n",
        "  \n",
        "mean, var, std = stats.bayes_mvs(exercise_df['exercise_time'], 0.5) \n",
        "  \n",
        "print (\"\\nMean of Exercise time : \", mean) \n",
        "print (\"\\nvar of Exercise time : \", var) \n",
        "print (\"\\nstd of Exercise time : \", std) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean of weight :  Mean(statistic=153.54083333333332, minmax=(151.87335296945872, 155.20831369720793))\n",
            "\n",
            "var of weight :  Variance(statistic=1233.2416659722223, minmax=(1150.4284174922657, 1316.054914452179))\n",
            "\n",
            "std of weight :  Std_dev(statistic=35.11754071645995, minmax=(33.938454043668806, 36.29662738925109))\n",
            "\n",
            "Mean of Exercise time :  Mean(statistic=134.91083333333333, minmax=(133.24581851531346, 136.5758481513532))\n",
            "\n",
            "var of Exercise time :  Variance(statistic=7312.514549305555, minmax=(7111.157669726946, 7513.871428884165))\n",
            "\n",
            "std of Exercise time :  Std_dev(statistic=85.51324195296046, minmax=(84.33589868436252, 86.6905852215584))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okkwCzwES20T",
        "colab_type": "text"
      },
      "source": [
        "# Summarazing Bayesian and Frequentist statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xAOF8G1S8FK",
        "colab_type": "text"
      },
      "source": [
        "The difference between Bayesian and Frequentist statistics is that in frequentist statistics you take samples of the data and based on those samples you infer the median of the data.\n",
        "\n",
        "In Bayesian has a full posterior distribution over the possible parameter values which allows to take into account the uncertainty in the estimate by integrating the full posterior distribution, instead of basing the prediction just on the most likely value. In Bayesian you update existing data with prior information for better inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    }
  ]
}